{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "pl.Config.set_tbl_rows(200)\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from make_clinical_dataset.shared.constants import INFO_DIR, ROOT_DIR\n",
    "from make_clinical_dataset.epic.preprocess.lab import clean_lab_data\n",
    "from make_clinical_dataset.epic.util import load_lab_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2025-03-29'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lab name mapping\n",
    "lab_map = load_lab_map(data_dir=INFO_DIR)\n",
    "\n",
    "# get the mrn mapping\n",
    "mrn_map = pd.read_csv(f'{INFO_DIR}/mrn_map.csv')\n",
    "mrn_map = mrn_map.set_index('PATIENT_RESEARCH_ID')['MRN'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(f'{ROOT_DIR}/data/processed/lab/lab_{date}/*.parquet').lazy()\n",
    "df = clean_lab_data(df, mrn_map, lab_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by('obs_name', 'obs_unit').len().sort('obs_name').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution bar plot for each unit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "summary = (\n",
    "    df\n",
    "    .group_by(\"obs_name\", \"obs_unit\")\n",
    "    .agg([pl.col(\"obs_val_num\").quantile(q).alias(f\"q{q:0.2f}\") for q in np.arange(0, 1, 0.01)])\n",
    ")\n",
    "summary = summary.sort('obs_name').collect().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = summary['obs_name'].nunique()\n",
    "nrows, ncols = n // 2, 2\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n",
    "axes = axes.flatten()\n",
    "for i, (name, group) in enumerate(summary.groupby('obs_name')):\n",
    "    for _, row in group.iterrows():\n",
    "        unit = row['obs_unit'] \n",
    "        if unit is None: unit = 'null'\n",
    "        vals = row.iloc[2:].to_list()\n",
    "        ticks = row.iloc[2:].index.to_list()\n",
    "        axes[i].bar(ticks, vals, label=unit, alpha=0.5)\n",
    "        axes[i].set_xticks(['q0.01', 'q0.25', 'q0.50', 'q0.75', 'q0.99'])\n",
    "        axes[i].set_title(name, fontdict={'fontsize': 10, 'fontweight': 'medium'})\n",
    "        axes[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## string entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.filter(pl.col('obs_val_str').is_not_null()).collect()\n",
    "tmp.group_by('proc_name', 'obs_val_str', 'obs_name', 'orig_obs_name').len().sort('len', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col, str_col = \"obs_val_num\", \"obs_val_str\"\n",
    "df.select(\n",
    "    (pl.col(num_col).is_not_null() & pl.col(str_col).is_null()).sum().alias('Only numerical entries'),\n",
    "    (pl.col(num_col).is_null() & pl.col(str_col).is_null()).sum().alias('Neither'),\n",
    "    (pl.col(num_col).is_not_null() & pl.col(str_col).is_not_null()).sum().alias('Both'),\n",
    "    (pl.col(num_col).is_null() & pl.col(str_col).is_not_null()).sum().alias('Only string entries')\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_date_col, secondary_date_col = \"effective_datetime\", \"occurrence_datetime_from_order\"\n",
    "df.select(\n",
    "    (pl.col(main_date_col).is_not_null() & pl.col(secondary_date_col).is_null()).sum().alias('Only effective_datetime'),\n",
    "    (pl.col(main_date_col).is_null() & pl.col(secondary_date_col).is_null()).sum().alias('Neither'),\n",
    "    (pl.col(main_date_col).is_not_null() & pl.col(secondary_date_col).is_not_null()).sum().alias('Both'),\n",
    "    (pl.col(main_date_col).is_null() & pl.col(secondary_date_col).is_not_null()).sum().alias('Only occurence_datetime_from_order')\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "both = df.filter(pl.col(main_date_col).is_not_null() & pl.col(secondary_date_col).is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often effective_datetime is earlier than occurence_datetime_from_order\n",
    "mask = pl.col(main_date_col) < pl.col(secondary_date_col)\n",
    "both.select(mask.value_counts().alias('earlier')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of the differences\n",
    "diff = pl.col(main_date_col) - pl.col(secondary_date_col)\n",
    "diff = both.select(diff.alias('diff')).collect().to_pandas()\n",
    "diff['diff'].dt.days.value_counts().head(100).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f'{ROOT_DIR}/data/final/data_{date}/interim/lab.parquet')\n",
    "df['obs_year'] = pd.to_datetime(df['obs_date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df['mrn'].nunique()\n",
    "min_date, max_date = df['obs_date'].min(), df['obs_date'].max()\n",
    "print(f'{N} patients from {min_date} to {max_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement counts over time\n",
    "cols = df.columns.drop(['mrn', 'obs_year', 'obs_date'])\n",
    "counts = df.groupby('obs_year').apply(lambda g: g[cols].notnull().sum(), include_groups=False)\n",
    "counts = counts.reset_index().melt('obs_year', var_name='lab_test', value_name='count')\n",
    "g = sns.relplot(\n",
    "    data=counts, x='obs_year', y='count', col='lab_test', col_wrap=3, kind='line', \n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall missingness\n",
    "df.isnull().mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients over time\n",
    "df.groupby('obs_year')['mrn'].nunique().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests per patients\n",
    "df.groupby('obs_year').apply(\n",
    "    lambda g: g.groupby('mrn').apply(len, include_groups=False).mean(),\n",
    "    include_groups=False\n",
    ").plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kevenv",
   "language": "python",
   "name": "kevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
