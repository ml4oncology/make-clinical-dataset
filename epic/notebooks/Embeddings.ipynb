{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from make_clinical_dataset.shared.constants import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = '2025-03-29'\n",
    "DATA_DIR = f\"{ROOT_DIR}/data/final/data_{DATE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## ED Risk Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take ALL notes within 5 days prior to a treatment session\n",
    "from make_clinical_dataset.epic.combine import get_clinic_prior_to_treatment\n",
    "clinic = pl.read_parquet(f'{DATA_DIR}/interim/clinic_visits.parquet')\n",
    "chemo = pl.read_parquet(f'{DATA_DIR}/interim/chemo.parquet')\n",
    "df = get_clinic_prior_to_treatment(clinic, chemo, lookback_window=5, strategy='all')\n",
    "df.write_parquet(f'{DATA_DIR}/interim/subsets/clinic_visits_prior_to_treatment/notes.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ml4o-batch-inference (see https://github.com/ml4oncology/ml4o-batch-inference)\n",
    "# Example of the SLURM script below\n",
    "\"\"\"\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=batch-inference\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --account=grantgroup_gpu\n",
    "#SBATCH --time=23:59:59\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --gres=gpu:l40:1\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem=32G\n",
    "#SBATCH --output=/cluster/home/%u/logs/%j.out\n",
    "#SBATCH --error=/cluster/home/%u/logs/%j.err\n",
    "\n",
    "mkdir -p /cluster/home/$USER/logs\n",
    "\n",
    "# Load Apptainer module\n",
    "module load apptainer\n",
    "\n",
    "# Load the paths\n",
    "source .env\n",
    "\n",
    "# Set up bind paths\n",
    "export APPTAINER_BINDPATH=$APPTAINER_BINDPATH,$MODEL_PATH\n",
    "\n",
    "# Run batch inference script inside the container\n",
    "apptainer exec --nv $IMAGE_PATH python3.10 ~/repos/ml4o-batch-inference/batch_inference.py \\\n",
    "        --data-path $DATA_PATH \\\n",
    "        --output-path $OUTPUT_PATH \\\n",
    "        --prompt-path ~/repos/make-clinical-dataset/epic/prompts/ed_risk_summarizer.txt \\\n",
    "        --model-name Qwen_Qwen3-14B-IQ4_XS.gguf \\\n",
    "        --tokenizer-path $LLM_PATH/Qwen3-14B \\\n",
    "        --max-model-len 5120 \\\n",
    "        --max-num-seqs 42 \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"/cluster/projects/gliugroup/work_dir/kevin_he/BatchInferOutput/ed_risk_summary/batch_infer/generated_output\"\n",
    "df = pl.read_parquet(f\"{OUTPUT_PATH}/*.parquet\")\n",
    "notes = pl.read_parquet(f'{DATA_DIR}/interim/subsets/clinic_visits_prior_to_treatment/notes.parquet', columns=['note_id', 'note'])\n",
    "df = df.join(notes, on='note_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into individual sections\n",
    "# TODO: fix from source, ensure guided regex with vllm\n",
    "\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "SECTION_MAP = {\n",
    "    \"=== ACTIVE SYMPTOMS ===\": \"active_symptoms\", \n",
    "    \"=== RECENT COMPLICATIONS / ADVERSE EVENTS ===\": \"recent_complications\",\n",
    "    \"=== RECENT HEALTHCARE UTILIZATION ===\": \"healthcare_utilization\",\n",
    "    \"=== FUNCTIONAL STATUS / DECLINE ===\": \"functional_status\",\n",
    "    \"=== MEDICATION-RELATED RISKS ===\": \"medication_risks\",\n",
    "    \"=== PSYCHOSOCIAL / SUPPORT RISKS ===\": \"psychosocial_risks\",\n",
    "    \"=== CLINICAL UNCERTAINTY / WATCHFUL WAITING ===\": \"clinical_uncertainty\",\n",
    "    \"=== OVERALL ACUITY ASSESSMENT ===\": \"acuity_assessment\",\n",
    "}\n",
    "\n",
    "\n",
    "# remove samples where section was not present\n",
    "# for section in SECTION_NAMES:\n",
    "#     mask = ~df['generated_output'].str.contains(section)\n",
    "#     print(f\"Excluding {mask.sum()} ({mask.mean()*100:.2f}%) samples without section {section}\")\n",
    "#     df = df.filter(~mask)\n",
    "\n",
    "data = []\n",
    "for text in tqdm(df['generated_output']):\n",
    "    res = {}\n",
    "\n",
    "    # get all the headers from the generated output\n",
    "    pattern = r\"===\\s*([^=]+)\\s*===\\n\"\n",
    "    matches = list(re.finditer(pattern, text))\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        header = text[match.start():match.end()]\n",
    "\n",
    "        # find the section that matches the header the closest (LLM does make typos unfortunately)\n",
    "        for section, name in SECTION_MAP.items():\n",
    "            score = fuzz.ratio(header, section)\n",
    "            if score >= 90:\n",
    "                break\n",
    "\n",
    "        # get the content of the section\n",
    "        section_start = match.end()\n",
    "        section_end = matches[i+1].start() if i < len(matches) - 1 else len(text)\n",
    "        content = text[section_start:section_end]\n",
    "\n",
    "        # clean up the content\n",
    "        content = content.strip()\n",
    "        if content == \"- None\": \n",
    "            content = None\n",
    "\n",
    "        # store in res\n",
    "        res[name] = content\n",
    "        \n",
    "    data.append(res)\n",
    "\n",
    "data = pl.DataFrame(data)\n",
    "data = data.with_columns(df['note_id']) # add the note id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kevenv",
   "language": "python",
   "name": "kevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
