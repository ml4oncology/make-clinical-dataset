{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2025-03-29'\n",
    "root_dir = '/cluster/projects/gliugroup/2BLAST'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f'{root_dir}/data/processed/ESAS/ESAS_{date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey names\n",
    "df['obs_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime\n",
    "\"\"\"\n",
    "Hmm, what's up with the 177k rows without a timestamp?\n",
    "Most likely the datetime is stored in the column Observations.Observation.meta.lastUpdated \n",
    "in the {raw_data_dir}/observation_csv/*-observations-meta.csv files\n",
    "\n",
    "Because it makes up only ~2.5% of the cases, I'm going to ignore them\n",
    "\n",
    "TODO: process the meta csv files and merge it with the main datasets (why was it even separated in the first place?)\n",
    "\"\"\"\n",
    "main_date_col, secondary_date_col = \"occurrence_datetime_from_order\", \"effective_datetime\"\n",
    "pd.DataFrame(\n",
    "    data=[[\n",
    "        (df[main_date_col].notna() & df[secondary_date_col].isna()).sum(),\n",
    "        (df[main_date_col].isna() & df[secondary_date_col].isna()).sum(),\n",
    "        (df[main_date_col].notna() & df[secondary_date_col].notna()).sum(),\n",
    "        (df[main_date_col].isna() & df[secondary_date_col].notna()).sum()\n",
    "    ]],\n",
    "    columns=[f'Only {main_date_col}', 'Neither', 'Both', f'Only {secondary_date_col}']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string entries\n",
    "num_col, str_col = \"obs_val_num\", \"obs_val_str\"\n",
    "pd.DataFrame(\n",
    "    data=[[\n",
    "        (df[num_col].notna() & df[str_col].isna()).sum(),\n",
    "        (df[num_col].isna() & df[str_col].isna()).sum(),\n",
    "        (df[num_col].notna() & df[str_col].notna()).sum(),\n",
    "        (df[num_col].isna() & df[str_col].notna()).sum()\n",
    "    ]],\n",
    "    columns=['Only numerical entries', 'Neither', 'Both', 'Only string entries']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f'{root_dir}/data/final/data_{date}/interim/symptom.parquet')\n",
    "df['obs_year'] = df['obs_date'].dt.year\n",
    "symp_cols = df.columns.drop(['mrn', 'obs_year', 'obs_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df['mrn'].nunique()\n",
    "min_date, max_date = df['obs_date'].min(), df['obs_date'].max()\n",
    "print(f'{N} patients from {min_date} to {max_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement count over time\n",
    "# NOTE: The completion rate of these surveys dropped from ~70% to ~30% during COVID and has never rebounded. \n",
    "# We might have to rethink on the relevance of these as features, if we want to use them for predicting future outcomes. \n",
    "counts = df.groupby('obs_year').apply(lambda g: g[symp_cols].notnull().sum(), include_groups=False)\n",
    "counts = counts.reset_index().melt('obs_year', var_name='symptom', value_name='count')\n",
    "g = sns.relplot(\n",
    "    data=counts, x='obs_year', y='count', col='symptom', col_wrap=3, kind='line', \n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score distribution\n",
    "fig, axes = plt.subplots(nrows=int(np.ceil(len(symp_cols)/2)), ncols=2, figsize=(10,20))\n",
    "axes = axes.flatten()\n",
    "for idx, col in enumerate(symp_cols): \n",
    "    sns.histplot(df[col], ax=axes[idx], discrete=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall missingness\n",
    "df.isnull().mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patients over time\n",
    "df.groupby('obs_year')['mrn'].nunique().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surveys per patient\n",
    "df.groupby('obs_year').apply(\n",
    "    lambda g: g.groupby('mrn').apply(len, include_groups=False).mean(),\n",
    "    include_groups=False\n",
    ").plot(kind='bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kevenv",
   "language": "python",
   "name": "kevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
